{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slYJRGUGWi7M",
        "colab_type": "text"
      },
      "source": [
        "# CE-40719: Deep Learning\n",
        "## HW3 - CNN / CNN Case Studies / CNN Applications\n",
        "(23 points)\n",
        "\n",
        "#### Name:\n",
        "#### Student No.:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9th3celWi7O",
        "colab_type": "text"
      },
      "source": [
        "In this assignment we go through the following topics:\n",
        "- Writing custome pytorch modules\n",
        "- Using `tensorboard` for logging and visualization\n",
        "- Data Augmentation\n",
        "- Saving / Loading Models\n",
        "\n",
        "Please Keep in mind that:\n",
        "- You can not use out-of-the-box pytorch modules (nn.Conv2d, nn.Linear, nn.BatchNorm, nn.Dropout, ...)\n",
        "- You can run this notebook on your computer. If you prefer using Google Colab you may lose some of the functionalities of `tensorboard` (like Projector). You can install `tensorboard` on your computer using package manager of your choice, and download `runs` folder from Google Colab and run it locally using `tensorboard --logdir=runs`.\n",
        "- Use the [documentation](https://pytorch.org/docs/stable/index.html).\n",
        "\n",
        "In this assignment we are going to train a convolutional neural network to classify images from [fashion-mnist](https://github.com/zalandoresearch/fashion-mnist) dataset. Fashion-mnist is a simple dataset containing 60000 training and 10000 test $28 \\times 28$ grayscale images of 10 different classes. Each class corresponds to a different kind of clothing. \n",
        "\n",
        "## 1. Setup (1.5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YefZWKdV2ehA",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VT1aKupTz902",
        "outputId": "c522307d-dfd0-4794-ecd9-07adc6de5197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(torch.__version__)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXRuw0bDZsft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For visualizing with tensorboard in Google Colab using ngrok\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "import os\n",
        "LOG_DIR = 'runs'\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oHj3j8MWi7U",
        "colab_type": "text"
      },
      "source": [
        "To easily train your model on different gpu devices or your computer's cpu you can define a `torch.device` object corresponding to that device and use `.to(device)` method to easily move modules or tensors to different devices. Pytorch provides helper functions in [torch.cuda](https://pytorch.org/docs/stable/cuda.html) package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8h2VI3dPWi7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf405c77-b685-4bb8-887f-c7b3738d98b0"
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# create a cpu device if cuda is not available or cuda_device=None otherwise\n",
        "# create a cuda:{cuda_device} device.\n",
        "#################################################################################\n",
        "cuda_device = torch.cuda.current_device()\n",
        "device = torch.cuda.device(cuda_device)\n",
        "pass\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "print(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.cuda.device object at 0x7fd6cc1e3be0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqxq0663Wi7X",
        "colab_type": "text"
      },
      "source": [
        "Fashion-mnist dataset is available in `torchvision.datasets` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gYm5KjpuQ0VX",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# Initialize and download trainset and testset with datasets.FashionMNIST and\n",
        "# transform data into torch.Tensor. Initialize trainloader and testloader with\n",
        "# given batch_size.\n",
        "#################################################################################\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "trainset = datasets.FashionMNIST(root='./data',\n",
        "                                    train=True,\n",
        "                                    download=True,\n",
        "                                    transform=transform)\n",
        "\n",
        "testset = datasets.FashionMNIST(root='./data',\n",
        "                                   train=False,\n",
        "                                   download=True,\n",
        "                                   transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size)\n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT_cx0bPWi7a",
        "colab_type": "text"
      },
      "source": [
        "To get a sense of data it is always helpfull to see a few of samples. We can do this using `tensorboard`. Please read [this](https://pytorch.org/docs/stable/tensorboard.html) documentation page to get familiar with tensorboard. Run the following cell to intialize a SummaryWriter and log some of the training images to tensorboard. You can run tensorboard using `tensorboard --logdir=runs` and view images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yOaW3VX4INws",
        "colab": {}
      },
      "source": [
        "writer = SummaryWriter('./runs/FashionMNIST')\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "img_grid = utils.make_grid(images[:16], nrow=4)\n",
        "\n",
        "writer.add_image('FashionMNIST', img_grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9hprG-YWi7e",
        "colab_type": "text"
      },
      "source": [
        "We can also visualize data (or any representation of it) using dimmensionality reduction techniques provided by tensorboard. The following cell adds raw pixel values as embeddings to visualize data. You can see visualizations in projector tab of tensorboard after running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bML1OI8kkmJv",
        "outputId": "238d799d-f926-489c-bc5c-aeef62a85a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "def select_n_random(data, labels, n=100):\n",
        "    perm = torch.randperm(len(data))\n",
        "    return data[perm][:n], labels[perm][:n]\n",
        "\n",
        "nimages, nlabels = select_n_random(trainset.data, trainset.targets)\n",
        "\n",
        "writer.add_embedding(nimages.view(-1, 28 * 28), \n",
        "                     metadata=[classes[label] for label in nlabels],\n",
        "                     label_img=nimages.unsqueeze(1), \n",
        "                     tag='raw_pixels')\n",
        "writer.flush()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bf05a710d6a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                      \u001b[0mlabel_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                      tag='raw_pixels')\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_embedding\u001b[0;34m(self, mat, metadata, label_img, global_step, tag, metadata_header)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mArgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0mtag\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mData\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mblobname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m               \u001b[0mGround\u001b[0m \u001b[0mtruth\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mBinary\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.io.gfile' has no attribute 'get_filesystem'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfXZrW89Wi7i",
        "colab_type": "text"
      },
      "source": [
        "## 2. Modules (7 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDSsz8SCWi7i",
        "colab_type": "text"
      },
      "source": [
        "In this part you will define all the required modules for a convolutional model. You can only use functional package `torch.nn.functional` unless stated otherwise.\n",
        "\n",
        "### 2.1 Convolution Module (1.5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lVXQl0hcScTT",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# define convolution parameters using nn.Parameter.\n",
        "# initialize weihgt using nn.init.kaiming_uniform and bias by zeroes\n",
        "# use F.conv2d in forward method.\n",
        "#################################################################################\n",
        "class Conv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True):\n",
        "        super(Conv2d, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = \n",
        "        return out\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yUuOnM3Wi7l",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Linear (Fully-connected) Module (1.5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiJ9vDc2QlrA",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# define parameters using nn.Parameter.\n",
        "# initialize weihgt using nn.init.kaiming_uniform and bias by zeroes\n",
        "# use F.linear in forward method.\n",
        "#################################################################################\n",
        "class Linear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, bias=True):\n",
        "        super(Linear, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = \n",
        "        return out\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK6RlWvdWi7o",
        "colab_type": "text"
      },
      "source": [
        "### 2.3 1D Batch Normalization Module (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe0lZDyeWi7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# define and intitialize running_mean and running_var by zeroes and ones\n",
        "# respectively.\n",
        "# define weight and bias using nn.Parameter. initialize weights to a \n",
        "# normal distribution (std=1) and bias to zero.\n",
        "# use F.batch_norm in forward method.\n",
        "# use self.training to differ between training and test phase.\n",
        "#################################################################################\n",
        "class BatchNorm(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(BatchNorm, self).__init__()\n",
        "        pass\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = \n",
        "        return out\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZo4bR0Wi7s",
        "colab_type": "text"
      },
      "source": [
        "### 2.4 2D Batch Normalization Module (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GP3vpuOWi7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# define and intitialize running_mean and running_var by zeroes and ones\n",
        "# respectively.\n",
        "# define weight and bias using nn.Parameter. initialize weights to a\n",
        "# normal distribution (std=1) and bias to zero.\n",
        "# use F.batch_norm in forward method.\n",
        "# use self.training to differ between training and test phase.\n",
        "# more info on 2d batch normalization:\n",
        "# https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network\n",
        "#################################################################################\n",
        "class BatchNorm2d(nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(BatchNorm2d, self).__init__()\n",
        "        pass\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = \n",
        "        return out\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLcxDR75Wi7v",
        "colab_type": "text"
      },
      "source": [
        "## 3. Model (3.5 pts)\n",
        "\n",
        "Using the modules defined in previous part define the following model:\n",
        "\n",
        "`[Conv2d(3, 3), channels=8, stride=1, padding=1] > [BatchNorm2d] > [relu]`\n",
        "\n",
        "`[Conv2d(5, 5), channels=16, stride=1, padding=0] > [BatchNorm2d] > [relu] > [max_pool2d(2, 2), stride=(2, 2), padding=0]`\n",
        "\n",
        "`[Conv2d(5, 5), channels=32, stride=1, padding=0] > [BatchNorm2d] > [relu] > [max_pool2d(2, 2), stride=(2, 2), padding=0]`\n",
        "\n",
        "`[Linear(128)] > [BatchNorm] > [relu]`\n",
        "\n",
        "`[Linear(64)] > [BatchNorm] > [relu]`        __(features)__\n",
        "\n",
        "`[Linear(10)]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HCsSJAXKbamz",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dropout=None):\n",
        "        super(Model, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        pass\n",
        "        return out, features\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hRGM3IDWi7z",
        "colab_type": "text"
      },
      "source": [
        "## 4. Training the Model (5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qyREDBZgWi7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, trainloader, testloader, device, num_epoches, label):\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# write the main training loop procedure:\n",
        "# move data to defined device\n",
        "# zero_grad optimizer\n",
        "# forward\n",
        "# compute loss using F.cross_entropy\n",
        "# backward\n",
        "# step the optimizer\n",
        "# accumulate running loss\n",
        "#################################################################################\n",
        "    for epoch in range(num_epoches):\n",
        "        print('EPOCH {:2d}:'.format(epoch + 1))\n",
        "        running_loss = 0.\n",
        "        for i, (x, y) in enumerate(trainloader):\n",
        "            pass\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "       \n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# compute test loss:\n",
        "# dont forget to change model mode from train to eval\n",
        "# write the code in a with torch.no_grad() block to prevent computing and \n",
        "# accumulating gradients\n",
        "# accumulate loss in test_loss variable\n",
        "#################################################################################\n",
        "            if i % 100 == 99:\n",
        "                test_loss = 0.\n",
        "                pass\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "                writer.add_scalars('loss/'+label, \n",
        "                                   {'train': running_loss/100, 'test': test_loss/len(testloader)},\n",
        "                                  global_step=epoch * len(trainloader) + i + 1)\n",
        "                writer.flush()\n",
        "                print('\\titeration {:4d}: training_loss = {:5f}, test_loss = {:5f}'.format(i + 1, running_loss/100, test_loss/len(testloader)))\n",
        "                running_loss = 0.\n",
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# compute test accuracy:\n",
        "# dont forget to change model mode from train to eval\n",
        "# write the code in a with torch.no_grad() block to prevent computing and \n",
        "# accumulating gradients\n",
        "# accumulate number of correct predictions in correct variable and total test\n",
        "# samples in total variable\n",
        "# accumulate number of classwise correct predictions in class_correct list \n",
        "# and total classwise test samples in class_total list\n",
        "#################################################################################\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            \n",
        "            class_correct = [0.] * 10\n",
        "            class_total = [0.] * 10\n",
        "            pass\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################\n",
        "        writer.add_scalars('accuracy/'+label, {'test': correct / total},\n",
        "                           global_step=(epoch + 1) * len(trainloader))\n",
        "        print('test_accuracy = {:5f}'.format(correct / total))\n",
        "        \n",
        "        writer.add_scalars('classwise_accuracy/'+label, \n",
        "                           {classes[i]: class_correct[i]/class_total[i] for i in range(10)},\n",
        "                           global_step=(epoch + 1) * len(trainloader))\n",
        "        for i in range(10):\n",
        "            print('  >> {:11s}: {:5f}'.format(classes[i], class_correct[i]/class_total[i]))\n",
        "            \n",
        "        writer.flush()\n",
        "        torch.save(model.state_dict(), './saved_models/model_{}.chkpt'.format(label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icG5VmKZWi72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# initilize model and train for 10 epoches using Adam optimizer\n",
        "#################################################################################\n",
        "num_epoches = 10\n",
        "pass\n",
        "\n",
        "writer.add_graph(model, images)\n",
        "train(model, optimizer, trainloader, testloader, device, num_epoches, 'base')\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJVizp04Wi74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# add model features corresponding to nimages as embedding to tensorboard\n",
        "#################################################################################\n",
        "pass\n",
        "writer.flush()\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5B2ypciWi76",
        "colab_type": "text"
      },
      "source": [
        "## 5. Dropout and Data Augmentation (6 pts)\n",
        "\n",
        "Add dropout with p=0.5 to first two linear layers of the model using `F.dropout`. You can either modify the model module to take an additional parameter or write a seperate module. \n",
        "\n",
        "Data Augmentation is a strategy for increasing dataset size to prevent overfitting and better generalization. Dataset can be augmented by any transformation on data that do not change its label.\n",
        "\n",
        "Pytorch provides data augmentation transforms in `torchvision.transforms` package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPLFEkNaWi77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# compose a transform using transforms.Compose that horizontally flips images \n",
        "# and use transforms.RandomResizedCrop to crop a 20 * 20 patch of the image \n",
        "# and resizing back to 28 * 28\n",
        "#################################################################################\n",
        "transform = \n",
        "trainset = \n",
        "testset = \n",
        "\n",
        "trainloader = \n",
        "testloader = \n",
        "\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdAsxVDNWi79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "img_grid = utils.make_grid(images[:16], nrow=4)\n",
        "\n",
        "writer.add_image('FashionMNIST/augmented', img_grid)\n",
        "writer.flush()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAz2wAJyWi7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# initilize model and train using augmented dataset for 10 epoches\n",
        "#################################################################################\n",
        "pass\n",
        "\n",
        "writer.add_graph(model, images)\n",
        "train(model2, optimizer, trainloader, testloader, device, num_epoches, 'dropout')\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FWwGvwiWi8B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#################################################################################\n",
        "#                          COMPLETE THE FOLLOWING SECTION                       #\n",
        "#################################################################################\n",
        "# add model features corresponding to nimages as embedding to tensorboard\n",
        "#################################################################################\n",
        "pass\n",
        "\n",
        "writer.flush()\n",
        "writer.close()\n",
        "#################################################################################\n",
        "#                                   THE END                                     #\n",
        "#################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}