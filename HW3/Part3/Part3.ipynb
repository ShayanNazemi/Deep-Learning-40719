{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Part3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "debde95a321e43d2a4e0ffb06e4523b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_926fc6d4bf4f435d88eda36acaa7e649",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e8d466e5ea24cc8b1956a32a3c1c8f1",
              "IPY_MODEL_10465e6e583c4ebc841651048ada7dd3"
            ]
          }
        },
        "926fc6d4bf4f435d88eda36acaa7e649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e8d466e5ea24cc8b1956a32a3c1c8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6f65354ecab44ff187bb70f4c6ed2670",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_014a9f96792e4ec6bc58094c2d2366b2"
          }
        },
        "10465e6e583c4ebc841651048ada7dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08a419d2fca54019af1085e1886beccc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:30&lt;00:00, 17027861.01it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a470602807c443739cf9ecc3d6640790"
          }
        },
        "6f65354ecab44ff187bb70f4c6ed2670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "014a9f96792e4ec6bc58094c2d2366b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08a419d2fca54019af1085e1886beccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a470602807c443739cf9ecc3d6640790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PhShOHkoCHQ4"
      },
      "source": [
        "# CE-40719: Deep Learning\n",
        "## HW3 - CNN / CNN Case Studies / CNN Applications\n",
        "(18 points)\n",
        "\n",
        "#### Name: Seyed Shayan Nazemi\n",
        "#### Student No.: 98209037"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E8SJVCBZxJQB"
      },
      "source": [
        "In this exercise we are going to implement a simple residual netwrok architecture to classify images from Cifar10 dataset. Here we give you a suggestion for architecture but you are allowed to  make changes and experiment to get better results. Explain your ideas or reference the papers that you take the ideas from. You are allowed to use out-of-the-box pytorch modules in `torch.nn`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8bd7O4pSrpL1"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "_All convolution layers have `3 * 3` kernel,  `padding=1`, batch normalization and relu activation_\n",
        "\n",
        "__ResidualBlock:__ _in_channel, out_channel, stride_\n",
        "\n",
        "- Conv(in_channel, out_channel, stride)\n",
        "- Conv(out_channel, out_channel, stride=1)\n",
        "\n",
        "`*` This block has a residual connection. To match dimmensions of output and residual use `1 * 1` convolution and stride. \n",
        "\n",
        "__ResidualLayer:__ _in_channel, out_channel, stride_\n",
        "\n",
        "- ResidualBlock(in_channel, out_channel, stride)\n",
        "- ResidualBlock(out_channel, out_channel, stride=1)\n",
        "\n",
        "__ResidualNetwork__:\n",
        "- Conv(3, 64, stride=1)\n",
        "- ResidualLayer(64, 64, stride=1)\n",
        "- ResidualLayer(64, 128, stride=2)\n",
        "- ResidualLayer(128, 256, stride=2)\n",
        "- ResidualLayer(256, 512, stride=2)\n",
        "- AveragePool(4, 4)\n",
        "- Linear(512, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QPDVsQXKokZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWDu_fpYQsQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_WORKERS = 4\n",
        "BATCH_SIZE = 32\n",
        "VAL_SIZE = 0.1\n",
        "N_EPOCHS = 10\n",
        "\n",
        "DEVICE = None\n",
        "if torch.cuda.is_available():\n",
        "    cuda_device = torch.cuda.current_device()\n",
        "    DEVICE = torch.device('cuda', cuda_device)\n",
        "else:\n",
        "    DEVICE = torch.device('cpu', 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vfiew1EVRCFv",
        "colab_type": "code",
        "outputId": "c9123783-1fb7-497b-96c1-a1f08fd929c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "debde95a321e43d2a4e0ffb06e4523b0",
            "926fc6d4bf4f435d88eda36acaa7e649",
            "5e8d466e5ea24cc8b1956a32a3c1c8f1",
            "10465e6e583c4ebc841651048ada7dd3",
            "6f65354ecab44ff187bb70f4c6ed2670",
            "014a9f96792e4ec6bc58094c2d2366b2",
            "08a419d2fca54019af1085e1886beccc",
            "a470602807c443739cf9ecc3d6640790"
          ]
        }
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_data = datasets.CIFAR10(root = 'data', train = True, download = True, transform = transform)\n",
        "\n",
        "test_data = datasets.CIFAR10(root = 'data', train = False, download = True, transform = transform)\n",
        "\n",
        "\n",
        "\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(num_train * VAL_SIZE))\n",
        "train_index, val_index = indices[split:], indices[:split]\n",
        "train_sampler = SubsetRandomSampler(train_index)\n",
        "val_sampler = SubsetRandomSampler(val_index)\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(train_data, sampler=val_sampler, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "debde95a321e43d2a4e0ffb06e4523b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8r-Vt2MLZHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvolutionLayer(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, stride, kernel_size=(3, 3) , padding=1):\n",
        "        super(ConvolutionLayer, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.batch = nn.BatchNorm2d(num_features=out_channel)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch(out)\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_0PbAClJexp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, stride):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = ConvolutionLayer(in_channel, out_channel, stride=stride)\n",
        "        self.conv2 = ConvolutionLayer(out_channel, out_channel, stride=1)\n",
        "\n",
        "        self.residual_conv = ConvolutionLayer(in_channel, out_channel, stride=stride, kernel_size=(1, 1), padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        \n",
        "        x_res = self.residual_conv(x)\n",
        "\n",
        "        out += x_res\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU6yWdYhKLyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualLayer(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, stride):\n",
        "        super(ResidualLayer, self).__init__()\n",
        "        self.res_block1 = ResidualBlock(in_channel, out_channel, stride=stride)\n",
        "        self.res_block2 = ResidualBlock(out_channel, out_channel, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.res_block1(x)\n",
        "        out = self.res_block2(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Iqbwxx_Jwyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.config = {\n",
        "            'conv' : (3, 64, 1), \n",
        "            'res1' : (64, 64, 1), \n",
        "            'res2' : (64, 128, 2), \n",
        "            'res3' : (128, 256, 2), \n",
        "            'res4' : (256, 512, 2),\n",
        "            'pool' : (4, 4),\n",
        "            'linear' : (512, 10)\n",
        "            }\n",
        "\n",
        "        self.conv = ConvolutionLayer(*self.config['conv'])\n",
        "        self.res1 = ResidualLayer(*self.config['res1'])\n",
        "        self.res2 = ResidualLayer(*self.config['res2'])\n",
        "        self.res3 = ResidualLayer(*self.config['res3'])\n",
        "        self.res4 = ResidualLayer(*self.config['res4'])\n",
        "        self.pool = nn.AvgPool2d(kernel_size=self.config['pool'])\n",
        "        self.linear = nn.Linear(*self.config['linear'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('input shape : ', x.shape)\n",
        "        out = self.conv(x)\n",
        "        # print('first conv output shape : ', out.shape)\n",
        "        out = self.res1(out)\n",
        "        # print('residual 1 output shape : ', out.shape)\n",
        "        out = self.res2(out)\n",
        "        # print('residual 2 output shape : ', out.shape)\n",
        "        out = self.res3(out)\n",
        "        # print('residual 3 output shape : ', out.shape)\n",
        "        out = self.res4(out)\n",
        "        # print('residual 4 output shape : ', out.shape)\n",
        "        out = self.pool(out)\n",
        "        # print('avg pooling output shape : ', out.shape)\n",
        "        # print('-------------------------------')\n",
        "        out = out.view(-1, 512)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GELabvQSP5cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, train_loader, val_loader, criterion, device, n_epochs):\n",
        "    val_loss_min = np.Inf\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = 0\n",
        "        model.train() # set the model state to train state - specially for dropout and batchnorm\n",
        "\n",
        "        for iteration, (data, label) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data.to(device))\n",
        "            loss = criterion(output, label.to(device))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.shape[0]\n",
        "\n",
        "            if iteration % 100 == 0:\n",
        "                is_training = model.training\n",
        "                val_loss = 0\n",
        "                model.eval()\n",
        "                acc_val = 0\n",
        "                with torch.no_grad():\n",
        "                    for data_val, label_val in val_loader:\n",
        "                        output_val = model(data_val.to(device))\n",
        "                        loss = criterion(output_val, label_val.to(device))\n",
        "                        val_loss += loss.item() * data_val.shape[0]\n",
        "                        acc_val += torch.sum(torch.argmax(output_val, dim=1) == label_val.to(device)).item()\n",
        "\n",
        "                val_loss /= len(val_loader.sampler) # averaging loss on all validation set\n",
        "                if val_loss <= val_loss_min :\n",
        "                    print('Iteration : {:4d} \\t Validation Accuracy : {:.6f} - Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(iteration, acc_val/len(val_loader.sampler), val_loss_min, val_loss))\n",
        "                    torch.save(model.state_dict(), 'model.pt')\n",
        "                    val_loss_min = val_loss\n",
        "\n",
        "            model.train(mode = is_training)\n",
        "        \n",
        "        train_loss /= len(train_loader.sampler)\n",
        "        print('Epoch : {} \\t Training loss {:.6f}'.format(epoch + 1, train_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcUtVwWNeUZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, device):\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            output = model(data.to(device))\n",
        "            pred = torch.argmax(output, dim = 1)\n",
        "            num_correct += torch.sum(pred == target.to(device)).item()\n",
        "\n",
        "    test_acc = num_correct / len(test_loader.sampler)\n",
        "    print('Test Accuracy: {:.2f}%\\n'.format(test_acc * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwF4vyEUTLw5",
        "colab_type": "code",
        "outputId": "cf9b448d-de73-4e9d-9781-560525cc7106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model = Model()\n",
        "model.to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = F.cross_entropy\n",
        "\n",
        "train(model, optimizer, train_loader, val_loader, criterion, DEVICE, N_EPOCHS)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration :    0 \t Validation Accuracy : 0.098400 - Validation loss decreased (inf --> 2.303356). Saving model ...\n",
            "Iteration :  100 \t Validation Accuracy : 0.303000 - Validation loss decreased (2.303356 --> 1.828679). Saving model ...\n",
            "Iteration :  400 \t Validation Accuracy : 0.369600 - Validation loss decreased (1.828679 --> 1.680462). Saving model ...\n",
            "Iteration :  500 \t Validation Accuracy : 0.420800 - Validation loss decreased (1.680462 --> 1.548161). Saving model ...\n",
            "Iteration :  700 \t Validation Accuracy : 0.471800 - Validation loss decreased (1.548161 --> 1.508607). Saving model ...\n",
            "Iteration :  800 \t Validation Accuracy : 0.544600 - Validation loss decreased (1.508607 --> 1.266929). Saving model ...\n",
            "Iteration :  900 \t Validation Accuracy : 0.550600 - Validation loss decreased (1.266929 --> 1.261069). Saving model ...\n",
            "Iteration : 1100 \t Validation Accuracy : 0.578400 - Validation loss decreased (1.261069 --> 1.182262). Saving model ...\n",
            "Epoch : 1 \t Training loss 1.422366\n",
            "Iteration :  100 \t Validation Accuracy : 0.627800 - Validation loss decreased (1.182262 --> 1.040493). Saving model ...\n",
            "Iteration :  400 \t Validation Accuracy : 0.640600 - Validation loss decreased (1.040493 --> 1.011076). Saving model ...\n",
            "Iteration :  600 \t Validation Accuracy : 0.667600 - Validation loss decreased (1.011076 --> 0.928804). Saving model ...\n",
            "Iteration :  700 \t Validation Accuracy : 0.665200 - Validation loss decreased (0.928804 --> 0.915106). Saving model ...\n",
            "Iteration :  800 \t Validation Accuracy : 0.674200 - Validation loss decreased (0.915106 --> 0.904305). Saving model ...\n",
            "Iteration :  900 \t Validation Accuracy : 0.691600 - Validation loss decreased (0.904305 --> 0.883043). Saving model ...\n",
            "Iteration : 1100 \t Validation Accuracy : 0.683400 - Validation loss decreased (0.883043 --> 0.882887). Saving model ...\n",
            "Iteration : 1400 \t Validation Accuracy : 0.697400 - Validation loss decreased (0.882887 --> 0.848186). Saving model ...\n",
            "Epoch : 2 \t Training loss 0.910816\n",
            "Iteration :    0 \t Validation Accuracy : 0.703800 - Validation loss decreased (0.848186 --> 0.839620). Saving model ...\n",
            "Iteration :  400 \t Validation Accuracy : 0.728200 - Validation loss decreased (0.839620 --> 0.784278). Saving model ...\n",
            "Iteration :  600 \t Validation Accuracy : 0.733400 - Validation loss decreased (0.784278 --> 0.748182). Saving model ...\n",
            "Iteration : 1100 \t Validation Accuracy : 0.757200 - Validation loss decreased (0.748182 --> 0.688219). Saving model ...\n",
            "Iteration : 1400 \t Validation Accuracy : 0.775600 - Validation loss decreased (0.688219 --> 0.646519). Saving model ...\n",
            "Epoch : 3 \t Training loss 0.702470\n",
            "Iteration :  200 \t Validation Accuracy : 0.788800 - Validation loss decreased (0.646519 --> 0.615176). Saving model ...\n",
            "Iteration : 1100 \t Validation Accuracy : 0.797000 - Validation loss decreased (0.615176 --> 0.583534). Saving model ...\n",
            "Epoch : 4 \t Training loss 0.556321\n",
            "Iteration :  700 \t Validation Accuracy : 0.806200 - Validation loss decreased (0.583534 --> 0.576673). Saving model ...\n",
            "Iteration : 1000 \t Validation Accuracy : 0.808800 - Validation loss decreased (0.576673 --> 0.563015). Saving model ...\n",
            "Iteration : 1400 \t Validation Accuracy : 0.821400 - Validation loss decreased (0.563015 --> 0.538472). Saving model ...\n",
            "Epoch : 5 \t Training loss 0.453911\n",
            "Iteration :  100 \t Validation Accuracy : 0.822000 - Validation loss decreased (0.538472 --> 0.529621). Saving model ...\n",
            "Iteration :  300 \t Validation Accuracy : 0.829200 - Validation loss decreased (0.529621 --> 0.525121). Saving model ...\n",
            "Iteration : 1400 \t Validation Accuracy : 0.834800 - Validation loss decreased (0.525121 --> 0.513371). Saving model ...\n",
            "Epoch : 6 \t Training loss 0.364900\n",
            "Iteration :    0 \t Validation Accuracy : 0.832800 - Validation loss decreased (0.513371 --> 0.512302). Saving model ...\n",
            "Epoch : 7 \t Training loss 0.283423\n",
            "Iteration :    0 \t Validation Accuracy : 0.835200 - Validation loss decreased (0.512302 --> 0.510105). Saving model ...\n",
            "Epoch : 8 \t Training loss 0.219622\n",
            "Epoch : 9 \t Training loss 0.169735\n",
            "Epoch : 10 \t Training loss 0.133358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOPpNBbCT1sT",
        "colab_type": "code",
        "outputId": "28a2860a-7580-4810-a03e-b8f624c698a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model = Model()\n",
        "model.to(DEVICE)\n",
        "model.load_state_dict(torch.load('model.pt'))\n",
        "test(model, test_loader, DEVICE)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 83.53%\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubrsznN3fHKy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}