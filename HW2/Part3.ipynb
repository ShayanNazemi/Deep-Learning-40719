{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uVVeVEgumZLg"
      },
      "source": [
        "# CE-40959: Deep Learning\n",
        "## HW2 - CIFAR-10 Classification (Pytorch)\n",
        "\n",
        "(18 points)\n",
        "\n",
        "### Deadline: 23 Esfand\n",
        "\n",
        "#### Name:\n",
        "#### Student No.:\n",
        "\n",
        "\n",
        "Please review `Pytorch Tutorial` notebook (materials of the TA classes) before coming to this notebook and you can use `pytorch.org` to learn how to use PyTorch classes and commands.\n",
        "\n",
        "In this part you have to implement MLP for Classification of CIFAR-10 dataset. \n",
        "\n",
        "PyTorch provides the elegantly designed modules and classes `torch.nn`, `torch.optim` , `Dataset` , and `DataLoader` to help you create and train neural networks. In this homework you use them for your implementations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v5alOnjtlGfy",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as \n",
        "# test for save"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGj-LMuWmx2q"
      },
      "source": [
        "#### 3.1. Load Data:\n",
        "\n",
        "Complete the followed cell for data loading. \n",
        "In this cell you have to normalize, split and shuffle data for learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kgv51um_lJiL",
        "colab": {}
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "trainloader = None\n",
        "validationloader = None\n",
        "testloader = None\n",
        "##################################################################################\n",
        "# TODO: Use 'torchvision.datasets.CIFAR-10' class for loading CIFAR-10 dataset.  #\n",
        "# This dataset has 50000 data for training and 10000 data for test and every     #\n",
        "# data has shape (3*32*32).                                                      #\n",
        "# Also Use 'torchvision.transforms.Compose' for common image transformations     #\n",
        "# such as normalization and use 'torch.utils.data.DataLoader' class that it      #\n",
        "# represents a Python iterable over a dataset and divides data to Batches.       #\n",
        "# Then Split data into 3 part: Train, Validation and Test. Finally,              #\n",
        "# save iterable data in 'trainloader', 'validationloader', 'testloader'.         #\n",
        "##################################################################################\n",
        "\n",
        "batch_size_train = 64\n",
        "batch_size_test = 64\n",
        "\n",
        "valid_size = 0.2\n",
        "\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(), \n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                ])\n",
        "\n",
        "train_validatation_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform\n",
        "    )\n",
        "\n",
        "num_train = len(train_validatation_set)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_validatation_set, batch_size=batch_size_train, \n",
        "    sampler=SubsetRandomSampler(indices[split:])\n",
        "    )\n",
        "\n",
        "validationloader = torch.utils.data.DataLoader(\n",
        "    train_validatation_set, batch_size=batch_size_train, \n",
        "    sampler=SubsetRandomSampler(indices[:split])\n",
        "    )\n",
        "\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False,download=True, transform=transform\n",
        "    )\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=batch_size_test , shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "##################################################################################\n",
        "#                               End of your code                                 #\n",
        "##################################################################################\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wdLQ8BpxEoZ-"
      },
      "source": [
        "#### 3.2. Load Data Test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eaOeLN3klZ9F",
        "colab": {}
      },
      "source": [
        "############################################################\n",
        "# Run the following code an check the size of each batch   #\n",
        "############################################################\n",
        "examples = enumerate(trainloader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "print('The size and type of each batch in ''trainloader'' is:')\n",
        "print(example_data.size())\n",
        "print(type(example_data))\n",
        "examples = enumerate(testloader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "print('\\nThe size and type of each batch in ''testloader'' is:')\n",
        "print(example_data.size())\n",
        "print(type(example_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cPMpTd230hLY",
        "colab": {}
      },
      "source": [
        "#####################################################################\n",
        "# Run the following code and see some of the samples in the dataset #\n",
        "#####################################################################\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images:\n",
        "for i in range(4):\n",
        "    img=torchvision.utils.make_grid(images[i])\n",
        "    ###########################################################\n",
        "    #  If you normalize data , here unnormalize them to see   # \n",
        "    #  clear them.                                            #\n",
        "    ###########################################################\n",
        "    m = 0.5\n",
        "    s = 0.5\n",
        "    img = img * s + m    # unnormalize\n",
        "    ###########################################################\n",
        "    #                   End of your code                      #\n",
        "    ###########################################################\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1,2, 0)))\n",
        "    plt.title(\"Target Labels: {}\".format(classes[labels[i]]))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TKpijVi0E1Zm"
      },
      "source": [
        "#### 3.3. Network Design:\n",
        "Design the layer of your network and select proper hyperparameter. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V8nfR7jqxTBO",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "######################################################################\n",
        "# TODO: Use 'torch.nn' module to design your network for CIFAR-10    #\n",
        "# classification. You have to implement the structure of MLP for it. #\n",
        "# In your design you don't have any limitation and you can use       #\n",
        "# Batch-norm layers, Drop-out layers and etc for generalization      #\n",
        "# improvement (if needed). Use classes and modules from 'torch.nn'.  #\n",
        "# In the following code, the 'MLP' class is your MLP network and     #\n",
        "# this class is inherited from nn.Module, so you can benefit         #\n",
        "# properties of the 'nn.Module'.You may complete '__init__()'        #\n",
        "# constructor by some classes like 'nn.ReLU()' or 'nn.Linear()'      #\n",
        "# to use them in the forward pass of your network.                   #\n",
        "######################################################################\n",
        "  \n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, D_in, H1, H2, D_out):\n",
        "        super(MLP, self).__init__()\n",
        "        \n",
        "        self.linear1 = torch.nn.Linear(D_in, H1)\n",
        "        self.batch1 = torch.nn.BatchNorm1d(H1)\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "\n",
        "        self.linear2 = torch.nn.Linear(H1, H2)\n",
        "        self.batch2 = torch.nn.BatchNorm1d(H2)\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        \n",
        "        self.linear3 = torch.nn.Linear(H2, D_out)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear1(x)\n",
        "        out = self.batch1(out)\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        out = self.linear2(out)\n",
        "        out = self.batch2(out)\n",
        "        out = self.relu2(out)\n",
        "        \n",
        "        out = self.linear3(out)\n",
        "        return out\n",
        "\n",
        "######################################################################\n",
        "#                          End of your code                          #\n",
        "######################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1dGyL8c8E-Rb"
      },
      "source": [
        "#### 3.4. Optimization Algorithm:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AXuefQ1GB7Ry",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "#############################################################################\n",
        "# TODO: Use a Classification Cross-Entropy loss.Then, use 'torch.optim'     #\n",
        "# module to optimize Cross-Entropy loss. You should select a optimization   #\n",
        "# algorithm and its hyperparameters like learning rate.                     #\n",
        "#############################################################################\n",
        "net = MLP(3072, 100, 50, len(classes))\n",
        "learning_rate = 1e-3\n",
        "criterion = torch.nn.functional.cross_entropy\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "#############################################################################\n",
        "#                             End of your code                              #\n",
        "#############################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3jL9GEnZFN-z"
      },
      "source": [
        "#### 3.5. Training:\n",
        "You have to tweak `hidden_dim`, `leanirng_rate`, `weight_scale`, `num_epochs` and `reg` and etc to get a validation accuracy above 50%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zJdyD46TZY0t",
        "colab": {}
      },
      "source": [
        "#######################################################\n",
        "# TODO: Feed the inputs data to the MLP network and   #\n",
        "# optimize Cross-Entropy loss by using target labels. #\n",
        "# Then update weights and biases.                     #\n",
        "#######################################################\n",
        "\n",
        "num_epochs=10\n",
        "num_batchs = len(trainloader)\n",
        "for epoch in range(num_epochs):\n",
        "    total_train=0\n",
        "    correct_train=0\n",
        "    running_loss = 0.0\n",
        "    for batch, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        \n",
        "        (b_size, n_channel, w, h) = inputs.shape\n",
        "        inputs = inputs.reshape(b_size, n_channel * w * h)\n",
        "\n",
        "        # zero the parameter gradients:\n",
        "        optimizer.zero_grad()\n",
        "        pass\n",
        "\n",
        "        # forward pass:\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        pass\n",
        "\n",
        "        # backward pass:\n",
        "        loss.backward()\n",
        "        pass\n",
        "\n",
        "        # optimization:\n",
        "        optimizer.step()\n",
        "\n",
        "        pass\n",
        "        #############################################\n",
        "        #           End of your code                #\n",
        "        #############################################\n",
        "        \n",
        "\n",
        "        # Results: \n",
        "        running_loss += loss.item()\n",
        "\n",
        "        total_train += labels.size(0)\n",
        "        _, predicted_train = torch.max(outputs.data, 1)\n",
        "        correct_train += (predicted_train == labels).sum().item()\n",
        "\n",
        "        if batch % (num_batchs/10) == ((num_batchs/10) -1):\n",
        "            print('[Batch %d / %d] loss: %.3f' %\n",
        "                  (batch + 1, num_batchs, running_loss / (num_batchs/10)))\n",
        "            running_loss = 0.0\n",
        "            torch.save(net.state_dict(), './model.pth')\n",
        "            torch.save(optimizer.state_dict(), './optimizer.pth')\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in validationloader:\n",
        "            images, labels = data\n",
        "\n",
        "            (b_size, n_channel, w, h) = images.shape\n",
        "            images = images.reshape(b_size, n_channel * w * h)\n",
        "            \n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_acc = correct / total\n",
        "    train_acc = correct_train / total_train\n",
        "    print('(Epoch %d / %d) train acc: %.2f%%; val_acc: %.2f%%' % (\n",
        "          epoch+1, num_epochs, 100*train_acc, 100*val_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pLES_37SM6_N"
      },
      "source": [
        "#### 3.6. Test: \n",
        "Run the following cell and test your network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lw4zW0GPM6cR",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "\n",
        "        (b_size, n_channel, w, h) = images.shape\n",
        "        images = images.reshape(b_size, n_channel * w * h)\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "test_acc = correct / total\n",
        "print('Accuracy of the network on the test images: %2f %%' % (100 * test_acc ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrnQkpyENTrR",
        "colab": {}
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "\n",
        "        (b_size, n_channel, w, h) = images.shape\n",
        "        images = images.reshape(b_size, n_channel * w * h)\n",
        "\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}